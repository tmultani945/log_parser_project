#!/usr/bin/env python3
"""
Payload Parser for NR5G Log Codes

This script parses binary payloads using metadata JSON files generated by extract_metadata.py.
It extracts fields based on their offset, length, and type information.

Usage:
    python parse_payload.py <metadata_json> <payload_hex>
    python parse_payload.py metadata_0xB823_v196610.json "02 00 03 00 01 01..."
"""

import json
import struct
import sys
from pathlib import Path
from typing import Dict, List, Any, Union
from datetime import datetime


class PayloadParser:
    """Parser for binary payloads using ICD metadata."""

    def __init__(self, metadata_path: str):
        """
        Initialize parser with metadata file.

        Args:
            metadata_path: Path to metadata JSON file
        """
        self.metadata_path = Path(metadata_path)
        self.metadata = self._load_metadata()

    def _load_metadata(self) -> Dict[str, Any]:
        """Load metadata from JSON file."""
        if not self.metadata_path.exists():
            raise FileNotFoundError(f"Metadata file not found: {self.metadata_path}")

        with open(self.metadata_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        if 'metadata' not in data:
            raise ValueError("Invalid metadata format: missing 'metadata' key")

        return data['metadata']

    def _hex_string_to_bytes(self, hex_string: str) -> bytes:
        """
        Convert hex string to bytes.

        Args:
            hex_string: Hex string like "02 00 03 00" or "02000300"

        Returns:
            Bytes object
        """
        # Remove spaces, newlines, and any non-hex characters
        clean_hex = ''.join(hex_string.split())

        # Convert to bytes
        try:
            return bytes.fromhex(clean_hex)
        except ValueError as e:
            raise ValueError(f"Invalid hex string: {e}")

    def _parse_field_value(self, payload: bytes, field: Dict[str, Any]) -> Union[int, bool, str]:
        """
        Parse a single field value from payload.

        Args:
            payload: Binary payload data
            field: Field metadata dictionary

        Returns:
            Parsed field value
        """
        offset_bytes = field['offset_bytes']
        length_bits = field['length_bits']
        type_name = field['type_name']

        # Check if we have enough data
        required_bytes = offset_bytes + (length_bits + 7) // 8
        if len(payload) < required_bytes:
            return f"<insufficient data: need {required_bytes} bytes, have {len(payload)}>"

        # Extract bytes for this field
        length_bytes = (length_bits + 7) // 8
        field_data = payload[offset_bytes:offset_bytes + length_bytes]

        # Parse based on type
        if type_name == "Uint8" or (type_name == "Bool" and length_bits == 8):
            value = field_data[0]
            if type_name == "Bool":
                return bool(value)
            return value

        elif type_name == "Uint16":
            if length_bytes >= 2:
                value = struct.unpack('<H', field_data[:2])[0]  # Little-endian
                return value
            return 0

        elif type_name == "Uint32":
            if length_bytes >= 4:
                value = struct.unpack('<I', field_data[:4])[0]  # Little-endian
                return value
            return 0

        elif type_name == "Uint64":
            if length_bytes >= 8:
                value = struct.unpack('<Q', field_data[:8])[0]  # Little-endian
                return value
            return 0

        elif type_name == "Enumeration":
            value = field_data[0]
            return value

        else:
            # For nested tables or unknown types, return hex representation
            return field_data.hex().upper()

    def _format_field_value(self, field: Dict[str, Any], value: Any) -> str:
        """
        Format field value for display with enumeration descriptions.

        Args:
            field: Field metadata dictionary
            value: Parsed value

        Returns:
            Formatted string
        """
        type_name = field['type_name']

        # Handle enumeration types with descriptions
        if type_name == "Enumeration" and isinstance(value, int):
            description = field.get('description', '')
            if description and 'Values:' in description:
                # Try to find the enum value in description
                lines = description.split('\n')
                for line in lines:
                    if line.strip().startswith(f'• {value} –'):
                        enum_name = line.split('–', 1)[1].strip()
                        return f"{value} ({enum_name})"
            return str(value)

        # Handle boolean
        elif isinstance(value, bool):
            return str(value)

        # Handle integers - show both decimal and hex for larger values
        elif isinstance(value, int):
            if type_name in ["Uint32", "Uint64"]:
                return f"{value} (0x{value:X})"
            elif type_name == "Uint16" and value > 255:
                return f"{value} (0x{value:04X})"
            else:
                return str(value)

        return str(value)

    def parse(self, payload_hex: str) -> Dict[str, Any]:
        """
        Parse payload using metadata.

        Args:
            payload_hex: Hex string of payload data

        Returns:
            Dictionary with parsed fields
        """
        # Convert hex to bytes
        payload = self._hex_string_to_bytes(payload_hex)

        result = {
            'logcode_id': self.metadata['logcode_id'],
            'logcode_name': self.metadata['logcode_name'],
            'version': self.metadata['target_version']['version'],
            'version_hex': self.metadata['target_version']['version_hex'],
            'payload_length': len(payload),
            'payload_hex': payload.hex().upper(),
            'parsed_at': datetime.now().isoformat(),
            'fields': {}
        }

        # Get the actual fields to parse from dependent_tables
        # The main table just references the dependent table
        if self.metadata.get('dependent_tables'):
            # Use the first dependent table (which contains the actual fields)
            table = self.metadata['dependent_tables'][0]
            fields = table['fields']
            result['table_name'] = table['table_name']
            result['table_number'] = table['table_number']
        else:
            fields = self.metadata['main_table']['fields']
            result['table_name'] = self.metadata['main_table']['table_name']
            result['table_number'] = self.metadata['main_table']['table_number']

        # Parse each field
        for field in fields:
            field_name = field['name']
            value = self._parse_field_value(payload, field)
            formatted_value = self._format_field_value(field, value)

            result['fields'][field_name] = {
                'value': value,
                'formatted': formatted_value,
                'type': field['type_name'],
                'offset_bytes': field['offset_bytes'],
                'length_bits': field['length_bits']
            }

        return result

    def format_output(self, parsed_data: Dict[str, Any]) -> str:
        """
        Format parsed data for console output.

        Args:
            parsed_data: Parsed data dictionary

        Returns:
            Formatted string
        """
        lines = []
        lines.append("=" * 80)
        lines.append(f"Log Code: {parsed_data['logcode_id']} - {parsed_data['logcode_name']}")
        lines.append(f"Version: {parsed_data['version']} ({parsed_data['version_hex']})")
        lines.append(f"Table: {parsed_data['table_number']} - {parsed_data['table_name']}")
        lines.append(f"Payload Length: {parsed_data['payload_length']} bytes")
        lines.append("=" * 80)
        lines.append("")

        lines.append("Parsed Fields:")
        lines.append("-" * 80)

        # Find max field name length for alignment
        max_name_len = max(len(name) for name in parsed_data['fields'].keys())

        for field_name, field_data in parsed_data['fields'].items():
            offset = field_data['offset_bytes']
            length = field_data['length_bits']
            formatted = field_data['formatted']

            lines.append(f"{field_name:<{max_name_len}} @ {offset:3d} ({length:3d} bits): {formatted}")

        lines.append("-" * 80)
        return "\n".join(lines)

    def save_json(self, parsed_data: Dict[str, Any], output_path: str):
        """
        Save parsed data to JSON file.

        Args:
            parsed_data: Parsed data dictionary
            output_path: Output file path
        """
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(parsed_data, f, indent=2, ensure_ascii=False)
        print(f"\nParsed data saved to: {output_path}")


def main():
    """Main entry point."""
    if len(sys.argv) < 3:
        print("Usage: python parse_payload.py <metadata_json> <payload_hex>")
        print("\nExample:")
        print('  python parse_payload.py metadata_0xB823_v196610.json "02 00 03 00 01 01..."')
        print("\nOr with file paths:")
        print('  python parse_payload.py data/output/metadata_0xB823_v196610.json "02 00 03 00..."')
        sys.exit(1)

    metadata_path = sys.argv[1]
    payload_hex = sys.argv[2]

    try:
        # Parse the payload
        parser = PayloadParser(metadata_path)
        parsed_data = parser.parse(payload_hex)

        # Print formatted output
        print(parser.format_output(parsed_data))

        # Optionally save to JSON
        if len(sys.argv) > 3:
            output_path = sys.argv[3]
            parser.save_json(parsed_data, output_path)

    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
